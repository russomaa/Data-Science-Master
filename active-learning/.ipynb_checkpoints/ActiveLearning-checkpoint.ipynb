{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning II\n",
    "### Modulo Active Learning \n",
    "#### Trabajo realizado por: \n",
    "Guillermo Climent <br>\n",
    "Rubén Gímenez<br>\n",
    "Mayra Russo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "El objetivo de este trabajo es ensayar los métodos de active learning vistos en clase sobre el dataset Semeion Handwritting Digit.\n",
    "### Active Learning \n",
    "Los algoritmos de Active Learning permiten proactivamente seleccionar un sub-set de ejemplos que deberán ser etiquetados de un conjunto de instancias sin etiquetar. AL se basa en etiquetar datos durante la fase de entrenamiento de una manera incremental y dinámica, de manera que permita al algoritmo identificar que etiquetas van a ser las más informativas para de ese modo aprenderlas más rápido. \n",
    "### Dataset \n",
    "El dataset consiste en 1593 registros y 256 variables. \n",
    "Cada registro representa un dígito manuscrito posteriormente digitalizado en tamaño 16 x 16 (256 dimensiones).\n",
    "Fuente: https://archive.ics.uci.edu/ml/datasets/Semeion+Handwritten+Digit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primera Tarea\n",
    "En esta primera parte vamos a realizar un programa para clasificar nuestras muestras combinando las diferentes estrategias de active learning y diversidad estudiadas, empleando un SVM como clasificador base. <br>\n",
    "<br>\n",
    "\n",
    "### Estrategias de Active Learning \n",
    "<b>MS (margin sampling) <br></b>\n",
    "Basado en las propiedades geométricas del SVM, esta estrategia minimiza la distancia hacía el hiperplano más cercano<br>\n",
    "<b>MCLU (multi-class label uncertainty) <br></b>\n",
    "Considera la confianza de las dos clases más probables<br>\n",
    "<b>SSC (significance space construction) <br></b>\n",
    "Esta heurística usa las muestras de entrenamiento para definir una segunda función de clasificación, la cual es empleada sobre el conjunto de candidatos para predecir que muestras son las más probables para convertirse en vectores soporte. <br> \n",
    "<b>nEQB (normalized entropy query bagging)<br> </b>\n",
    "Modelo basado en la consideración de un comité de métodos de aprendizaje. Esta estrategia propone bagging para crear el comité.\n",
    "<br>\n",
    "<br>\n",
    "### Algoritmos 'diversity'\n",
    "Una vez se han seleccionado las muestras dentro de los conjuntos de candidatos, es importante asegurarse que estos son lo suficientemente diversos antes de añadirlos al conjunto de entrenamiento. <br>\n",
    "<br>\n",
    "<b>MAO: most ambiguous and orthogonal <br></b>\n",
    "Esta estrategia se basa en escoger muestras que minimicen los valores más altos dentro de la lista de candidatos. <br>\n",
    "<b>MCLU-ABD: multiclass level uncertainty-angle-based diversity <br></b>\n",
    "Esta estrategia combina el criterio MAO, con MCLU, llevándose a cabo mediante la selección de un subset de nuestro conjunto de candidatos que maximice el criterio de MCLU. <br>\n",
    "<b>Diversity by clustering <br></b>\n",
    "Esta última estrategia se encarga de asegurar la diversidad mediante clustering en el espacio de características. \n",
    "<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

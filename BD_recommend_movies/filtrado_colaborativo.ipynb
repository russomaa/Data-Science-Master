{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistema de Recomendación (Filtrado Colaborativo)\n",
    "\n",
    "- Escribir una implementación del mismo para Spark\n",
    "- Evaluar el modelo de filtrado colaborativo sobre el dataset de películas (Movies)\n",
    "\n",
    "### Big Data, Máster Ciencia de Datos\n",
    "#### Mayra Russo Botero "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=666\n",
    "\n",
    "# libraries\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext,SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder,CrossValidator\n",
    "from pyspark.sql.functions import col,min,max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e5c0c5fb3056>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# check if spark context is defined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# initialize SQLContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msqlContext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \"\"\"\n\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\pyspark\\java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;31m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# check if spark context is defined\n",
    "sc = SparkContext()\n",
    "\n",
    "# initialize SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# initialize Spark Session\n",
    "spark = SparkSession.builder.appName('rec_app').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import\n",
    "#users data\n",
    "u_cols = 'user_id::sex::age::occupation::zip_code'.split('::')\n",
    "df_users = sqlContext.read.csv('data/users.dat', sep=':',header=False,\n",
    "                               inferSchema=True)\n",
    "#ratings data\n",
    "r_cols = 'userID::movieID::rating::timestamp'.split('::')\n",
    "df_ratings = sqlContext.read.csv('data/ratings.dat', sep=':',header=False,\n",
    "                                 inferSchema=True)\n",
    "#movies data\n",
    "m_cols = 'movie_id::title::genres'.split('::')\n",
    "df_movies = sqlContext.read.csv('data/movies.dat', sep=':',header=False,\n",
    "                               inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userID: integer (nullable = true)\n",
      " |-- movieID: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n",
      "+------+-------+------+---------+\n",
      "|userID|movieID|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|   1193|     5|978300760|\n",
      "|     1|    661|     3|978302109|\n",
      "|     1|    914|     3|978301968|\n",
      "|     1|   3408|     4|978300275|\n",
      "|     1|   2355|     5|978824291|\n",
      "|     1|   1197|     3|978302268|\n",
      "|     1|   1287|     5|978302039|\n",
      "|     1|   2804|     5|978300719|\n",
      "|     1|    594|     4|978302268|\n",
      "|     1|    919|     4|978301368|\n",
      "|     1|    595|     5|978824268|\n",
      "|     1|    938|     4|978301752|\n",
      "|     1|   2398|     4|978302281|\n",
      "|     1|   2918|     4|978302124|\n",
      "|     1|   1035|     5|978301753|\n",
      "|     1|   2791|     4|978302188|\n",
      "|     1|   2687|     3|978824268|\n",
      "|     1|   2018|     4|978301777|\n",
      "|     1|   3105|     5|978301713|\n",
      "|     1|   2797|     4|978302039|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#arrange dataframes \n",
    "#extract correct columns and rename them, plus add headers \n",
    "#ratings df \n",
    "dis_columns = np.array(df_ratings.columns)\n",
    "dis_columns = dis_columns[range(0, len(df_ratings.columns), 2)]\n",
    "df_ratings = df_ratings.select(dis_columns.tolist())\n",
    "\n",
    "assert len(r_cols) == len(dis_columns)\n",
    "for i in range(len(r_cols)):\n",
    "    df_ratings = \\\n",
    "        df_ratings.withColumnRenamed(dis_columns[i], r_cols[i])\n",
    "df_ratings.printSchema()\n",
    "df_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "+--------+--------------------+--------------------+\n",
      "|movie_id|               title|              genres|\n",
      "+--------+--------------------+--------------------+\n",
      "|       1|    Toy Story (1995)|Animation|Childre...|\n",
      "|       2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|       3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|       4|Waiting to Exhale...|        Comedy|Drama|\n",
      "|       5|Father of the Bri...|              Comedy|\n",
      "|       6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|       7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|       8| Tom and Huck (1995)|Adventure|Children's|\n",
      "|       9| Sudden Death (1995)|              Action|\n",
      "|      10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|      11|American Presiden...|Comedy|Drama|Romance|\n",
      "|      12|             Dracula|                null|\n",
      "|      13|        Balto (1995)|Animation|Children's|\n",
      "|      14|        Nixon (1995)|               Drama|\n",
      "|      15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|      16|       Casino (1995)|      Drama|Thriller|\n",
      "|      17|Sense and Sensibi...|       Drama|Romance|\n",
      "|      18|   Four Rooms (1995)|            Thriller|\n",
      "|      19|         Ace Ventura|                null|\n",
      "|      20|  Money Train (1995)|              Action|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#movies df \n",
    "dis_columns1 = np.array(df_movies.columns)\n",
    "dis_columns1 = dis_columns1[range(0, len(df_movies.columns), 2)]\n",
    "df_movies = df_movies.select(dis_columns1.tolist())\n",
    "\n",
    "assert len(m_cols) == len(dis_columns1)\n",
    "for i in range(len(m_cols)):\n",
    "    df_movies = \\\n",
    "        df_movies.withColumnRenamed(dis_columns1[i], m_cols[i])\n",
    "df_movies.printSchema()\n",
    "df_movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- occupation: integer (nullable = true)\n",
      " |-- zip_code: string (nullable = true)\n",
      "\n",
      "+-------+---+---+----------+--------+\n",
      "|user_id|sex|age|occupation|zip_code|\n",
      "+-------+---+---+----------+--------+\n",
      "|      1|  F|  1|        10|   48067|\n",
      "|      2|  M| 56|        16|   70072|\n",
      "|      3|  M| 25|        15|   55117|\n",
      "|      4|  M| 45|         7|   02460|\n",
      "|      5|  M| 25|        20|   55455|\n",
      "|      6|  F| 50|         9|   55117|\n",
      "|      7|  M| 35|         1|   06810|\n",
      "|      8|  M| 25|        12|   11413|\n",
      "|      9|  M| 25|        17|   61614|\n",
      "|     10|  F| 35|         1|   95370|\n",
      "|     11|  F| 25|         1|   04093|\n",
      "|     12|  M| 25|        12|   32793|\n",
      "|     13|  M| 45|         1|   93304|\n",
      "|     14|  M| 35|         0|   60126|\n",
      "|     15|  M| 25|         7|   22903|\n",
      "|     16|  F| 35|         0|   20670|\n",
      "|     17|  M| 50|         1|   95350|\n",
      "|     18|  F| 18|         3|   95825|\n",
      "|     19|  M|  1|        10|   48073|\n",
      "|     20|  M| 25|        14|   55113|\n",
      "+-------+---+---+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#users df \n",
    "dis_columns2 = np.array(df_users.columns)\n",
    "dis_columns2 = dis_columns2[range(0, len(df_users.columns), 2)]\n",
    "df_users = df_users.select(dis_columns2.tolist())\n",
    "\n",
    "assert len(u_cols) == len(dis_columns2)\n",
    "for i in range(len(u_cols)):\n",
    "    df_users = \\\n",
    "        df_users.withColumnRenamed(dis_columns2[i], u_cols[i])\n",
    "df_users.printSchema()\n",
    "df_users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userID|count|\n",
      "+------+-----+\n",
      "|   148|  624|\n",
      "|   463|  123|\n",
      "|   471|  105|\n",
      "|   496|  119|\n",
      "|   833|   21|\n",
      "|  1088| 1176|\n",
      "|  1238|   45|\n",
      "|  1342|   92|\n",
      "|  1580|   37|\n",
      "|  1591|  314|\n",
      "|  1645|  522|\n",
      "|  1829|   30|\n",
      "|  1959|   61|\n",
      "|  2122|  208|\n",
      "|  2142|   77|\n",
      "|  2366|   41|\n",
      "|  2659|  161|\n",
      "|  2866|  205|\n",
      "|  3175|   87|\n",
      "|  3749|  118|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|        20|\n",
      "+----------+\n",
      "\n",
      "+----------+\n",
      "|max(count)|\n",
      "+----------+\n",
      "|      2314|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#extracting distinct user ids and movies, sparsity \n",
    "#number of ratings in matrix\n",
    "numerator = df_ratings.count()\n",
    "#distinct users and movies \n",
    "users=df_ratings.select('userID').distinct().count()\n",
    "movies=df_ratings.select('movieID').distinct().count()\n",
    "#number of ratings matrix could contain if no empty cells \n",
    "denominator = users * movies \n",
    "\n",
    "#calculating sparsity\n",
    "sparsity = 1 - (numerator*1.0 / denominator)\n",
    "sparsity\n",
    "\n",
    "#removes users with less than 20 ratings\n",
    "df_ratings.groupBy(\"userID\").count().filter(col(\"count\") >= 20).show()\n",
    "\n",
    "# max and min num of ratings by userId\n",
    "df_ratings.groupBy(\"userID\").count().select(min(\"count\")).show()\n",
    "df_ratings.groupBy(\"userID\").count().select(max(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Best Model**\n",
      "RMSE =  1.0454524726183856\n",
      " Rank:  50\n",
      " MaxIter:  5\n",
      " RegParam:  0.1\n"
     ]
    }
   ],
   "source": [
    "#fitting the model \n",
    "#we will use a smaller dataset \n",
    "(small_ratings,everything)= df_ratings.randomSplit([0.1,0.9],seed=SEED)\n",
    "# split data\n",
    "(training_data, test_data) = small_ratings.randomSplit([0.8, 0.2],seed=SEED)\n",
    "# ALS model\n",
    "als = ALS(userCol=\"userID\", itemCol=\"movieID\", ratingCol=\"rating\", nonnegative=True,\n",
    "coldStartStrategy=\"drop\", implicitPrefs=False)\n",
    "\n",
    "\n",
    "#create a ParamGridBuilder \n",
    "param_grid = ParamGridBuilder()\\\n",
    "            .addGrid(als.rank,[10, 50]) \\\n",
    "            .addGrid(als.maxIter,[5]) \\\n",
    "            .addGrid(als.regParam,[.05, .1, 1.5]) \\\n",
    "            .build()\n",
    "                      \n",
    "#how to evaluate performance\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "predictionCol=\"prediction\")\n",
    "\n",
    "#create cross validator\n",
    "cv = CrossValidator(estimator = als,\n",
    "                    estimatorParamMaps = param_grid,\n",
    "                    evaluator = evaluator,\n",
    "                    numFolds = 2)\n",
    "\n",
    "# Run the cv on the training data\n",
    "model = cv.fit(training_data)\n",
    "# Extract best combination of values from cross validation\n",
    "best_model = model.bestModel\n",
    "\n",
    "# Generate test set predictions and evaluate using RMSE\n",
    "predictions = best_model.transform(test_data)\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "# Print evaluation metrics and model parameters\n",
    "print (\"**Best Model**\")\n",
    "print (\"RMSE = \" , rmse)\n",
    "print (\" Rank: \", best_model.rank)\n",
    "print (\" MaxIter: \", best_model._java_obj.parent().getMaxIter())\n",
    "print (\" RegParam: \", best_model._java_obj.parent().getRegParam())\n",
    "#due to using a smaller data set, the performance of the model is worse than if training the model with a larger dataset.\n",
    "#however, due to the computational power and the resources available, we will keep the smaller dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+----------+\n",
      "|userID|movieID|rating|timestamp|prediction|\n",
      "+------+-------+------+---------+----------+\n",
      "|  1242|    148|     3|974909976| 2.5737453|\n",
      "|  2507|    148|     4|974082717| 2.7863207|\n",
      "|  3425|    471|     4|967364970|  4.145903|\n",
      "|  1404|    471|     3|974765002|  3.461893|\n",
      "|    26|    471|     4|978140977|  3.971983|\n",
      "|  3792|    471|     3|967123821| 3.7582922|\n",
      "|  1125|    471|     3|974923365|  3.181326|\n",
      "|  1377|    471|     1|974770883| 3.0990922|\n",
      "|  5556|    471|     5|959444046| 3.2658684|\n",
      "|  3031|    471|     5|970429234|  4.228343|\n",
      "|    95|    471|     3|977628135| 3.8344915|\n",
      "|  1980|    471|     4|974691272| 3.8825483|\n",
      "|  1983|    471|     5|976898914|  4.352147|\n",
      "|   934|    471|     5|991940804| 2.6414475|\n",
      "|  1298|    833|     2|974835615| 1.9081663|\n",
      "|  5046|    833|     2|962506488| 1.6108062|\n",
      "|  4725|   1088|     4|963456486| 2.8618388|\n",
      "|  3601|   1088|     4|966641981|  3.757358|\n",
      "|  4823|   1088|     2|963174317| 2.7987018|\n",
      "|  4521|   1088|     5|964835534| 3.3830276|\n",
      "+------+-------+------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### \n",
    "predictions.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
